# ğŸš€ FILEBOSS APEX INTEGRATION

## Complete Orchestration Guide

**Context Global:** `LFVBLPUL3N8N8K2FLYGCSCKMSMSRHSG9`  
**Context Direct:** `yD4IKCdlI0VCXlfD4xLT1x5D0dEU9Hd1`

---

## ğŸ¯ Overview

FILEBOSS now features **complete APEX orchestration**, connecting:

### Memory Triad (Triple Memory Architecture)
1. **Memory Plugin MCP** - Session persistence layer
2. **Supermemory AI MCP** - Universal memory with OAuth
3. **Mem0 API** - Graph memory with contradiction detection

### MCP Server Constellation
4. **GitHub MCP** - Access to 538+ repositories
5. **Notion MCP** - Complete documentation workspace
6. **Operator Code MCP** - 4,000+ specialized agent tools

---

## ğŸ› ï¸ Architecture

```
FILEBOSS v2.0.0-APEX
â”‚
â”œâ”€â”€ ğŸ›ï¸ CaseBuilder Core
â”‚   â”œâ”€â”€ FastAPI application
â”‚   â”œâ”€â”€ SQLAlchemy database
â”‚   â”œâ”€â”€ Cascade AI integration
â”‚   â””â”€â”€ REST API endpoints
â”‚
â”œâ”€â”€ ğŸ§  Memory Triad
â”‚   â”œâ”€â”€ Memory Plugin MCP (ws://localhost:8000/memory-plugin-mcp)
â”‚   â”œâ”€â”€ Supermemory AI MCP (api.supermemory.ai/mcp)
â”‚   â””â”€â”€ Mem0 API (api.mem0.ai/v1)
â”‚
â”œâ”€â”€ ğŸŒ MCP Orchestrator
â”‚   â”œâ”€â”€ GitHub operations
â”‚   â”œâ”€â”€ Notion operations
â”‚   â””â”€â”€ Operator Code delegation
â”‚
â””â”€â”€ ğŸš€ APEX API Layer
    â”œâ”€â”€ /apex/health - System health
    â”œâ”€â”€ /apex/process - File processing
    â”œâ”€â”€ /apex/search - Intelligent search
    â”œâ”€â”€ /apex/delegate - Task delegation
    â”œâ”€â”€ /apex/memory/* - Memory operations
    â””â”€â”€ /apex/stats - Integration statistics
```

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Install base requirements
pip install -r requirements.txt
pip install -r requirements-prod.txt

# Install APEX integration dependencies
pip install httpx  # For async HTTP requests
```

### 2. Set Environment Variables

Create `.env` file:

```bash
# Database
DATABASE_URL=sqlite+aiosqlite:///./fileboss.db

# Memory Systems
MEM0_API_KEY=your_mem0_api_key_here

# MCP Servers
GITHUB_TOKEN=your_github_pat_here
NOTION_TOKEN=your_notion_integration_token_here

# Context IDs (Pre-configured)
CONTEXT_GLOBAL=LFVBLPUL3N8N8K2FLYGCSCKMSMSRHSG9
CONTEXT_DIRECT=yD4IKCdlI0VCXlfD4xLT1x5D0dEU9Hd1
```

### 3. Start MCP Servers

```bash
# Memory Plugin MCP
npx -y @memoryplugin/mcp-server

# Supermemory AI MCP (OAuth)
npx -y install-mcp@latest https://api.supermemory.ai/mcp --client Qwen --oauth=yes
```

### 4. Start FILEBOSS

```bash
# Development mode (with auto-reload)
python main.py

# Production mode
gunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

---

## ğŸ“š API Endpoints

### System Endpoints

#### `GET /health`
Comprehensive health check of all integrated systems.

```json
{
  "status": "ok",
  "version": "2.0.0-APEX",
  "integration": "APEX Quantum Entangled",
  "services": {
    "database": "ğŸŸ¢ OK",
    "cascade_ai": "ğŸŸ¢ OK",
    "apex": {
      "status": "ğŸŸ¢ OK",
      "systems": {
        "memory_plugin": "ğŸŸ¢ OK",
        "supermemory": "ğŸŸ¢ OK",
        "github": "ğŸŸ¢ OK",
        "notion": "ğŸŸ¢ OK",
        "operator_code": "ğŸŸ¡ UNKNOWN"
      }
    }
  }
}
```

### APEX Orchestration Endpoints

#### `GET /apex/health`
APEX-specific health check.

#### `POST /apex/process`
Process a file through the complete APEX pipeline.

```json
{
  "file_path": "/path/to/document.pdf",
  "metadata": {
    "type": "evidence",
    "case": "1FDV-23-0001009"
  },
  "bucket": "fileboss_evidence"
}
```

**Response:**
```json
{
  "status": "success",
  "file": "/path/to/document.pdf",
  "result": {
    "memory_storage": {
      "memory_plugin": {"id": "mem_123"},
      "supermemory": {"id": "super_456"},
      "mem0": {"id": "m0_789"}
    },
    "github_sync": {"status": "success"},
    "notion_index": {"status": "success"}
  }
}
```

#### `POST /apex/search`
Intelligent multi-source search across all integrated systems.

```json
{
  "query": "case evidence filings 2023",
  "limit": 20
}
```

#### `POST /apex/delegate`
Delegate complex tasks to Operator Code MCP.

```json
{
  "task": "Analyze all evidence files for case 1FDV-23-0001009",
  "context": {
    "case_id": "1FDV-23-0001009",
    "document_type": "evidence"
  },
  "priority": "high"
}
```

#### `POST /apex/memory/store`
Store content across Memory Triad.

```json
{
  "content": "Important case note: Judge ruled in favor",
  "bucket": "case_notes",
  "metadata": {
    "case": "1FDV-23-0001009",
    "date": "2025-11-27"
  }
}
```

#### `GET /apex/memory/recall`
Recall memories from all three systems.

```
GET /apex/memory/recall?query=judge ruling&bucket=case_notes&limit=10
```

#### `POST /apex/batch-process`
Batch process multiple files in parallel.

```json
{
  "file_paths": [
    "/evidence/doc1.pdf",
    "/evidence/doc2.pdf",
    "/evidence/doc3.pdf"
  ],
  "parallel": true,
  "bucket": "batch_evidence"
}
```

#### `POST /apex/upload`
Upload and immediately process a file.

```bash
curl -X POST "http://localhost:8000/apex/upload" \
  -F "file=@document.pdf" \
  -F "bucket=uploads"
```

#### `GET /apex/stats`
Get comprehensive APEX integration statistics.

---

## ğŸ§  Memory Triad Usage

### Python API

```python
from integrations.apex_orchestrator import get_orchestrator

# Initialize
orchestrator = await get_orchestrator()

# Store memory across all three systems
result = await orchestrator.memory_triad.store(
    content="Important information to remember",
    bucket="my_bucket",
    metadata={"source": "manual_entry", "priority": "high"}
)

# Recall from all three systems
results = await orchestrator.memory_triad.recall(
    query="important information",
    bucket="my_bucket",
    limit=10
)

print(f"Found in Memory Plugin: {results['memory_plugin']}")
print(f"Found in Supermemory: {results['supermemory']}")
print(f"Found in Mem0: {results['mem0']}")
```

---

## ğŸ™ GitHub MCP Integration

```python
# Execute GitHub operations
result = await orchestrator.mcp_orchestrator.github_operation(
    operation="list_repos",
    limit=100
)

if result["status"] == "success":
    repos = result["data"]
    print(f"Found {len(repos)} repositories")
```

---

## ğŸ““ Notion MCP Integration

```python
# Search Notion workspace
result = await orchestrator.mcp_orchestrator.notion_operation(
    operation="search",
    query="FILEBOSS documentation"
)

if result["status"] == "success":
    pages = result["data"]["results"]
    for page in pages:
        print(f"Found: {page['properties']['title']}")
```

---

## ğŸ¤– Operator Code MCP Delegation

```python
# Delegate complex task
result = await orchestrator.operator_delegate(
    task="Process all PDF files in evidence folder",
    context={
        "folder": "/evidence",
        "file_type": "pdf",
        "action": "index_and_analyze"
    }
)

if result["status"] == "success":
    print(f"Task completed: {result['data']}")
```

---

## ğŸ›¡ï¸ Security & Configuration

### Required Permissions

**GitHub Token Scopes:**
- `repo` - Repository access
- `read:org` - Organization access
- `read:user` - User profile access

**Notion Integration:**
- Internal integration with read/write permissions
- Access to all relevant databases and pages

**Memory Systems:**
- Mem0 API key from [mem0.ai](https://mem0.ai)
- Supermemory OAuth setup via MCP installer
- Memory Plugin running locally or accessible endpoint

---

## ğŸ“Š Monitoring & Observability

### Health Checks

```bash
# Full system health
curl http://localhost:8000/health

# APEX-specific health
curl http://localhost:8000/apex/health

# Integration statistics
curl http://localhost:8000/apex/stats
```

### Logging

Logs are structured and include:
- Timestamp
- Logger name
- Log level
- Message

```python
import logging
logger = logging.getLogger(__name__)
```

---

## ğŸš€ Production Deployment

### Docker Deployment

```bash
# Build image
docker build -t fileboss-apex:latest .

# Run container
docker run -d \
  --name fileboss \
  -p 8000:8000 \
  --env-file .env \
  fileboss-apex:latest
```

### Environment-Specific Configurations

**Development:**
```bash
export ENVIRONMENT=development
export LOG_LEVEL=DEBUG
export RELOAD=True
```

**Production:**
```bash
export ENVIRONMENT=production
export LOG_LEVEL=INFO
export WORKERS=4
```

---

## ğŸ§‘â€ğŸ’» Developer Guide

### Adding New Integrations

1. **Create integration module** in `integrations/`
2. **Extend `ApexFileBossOrchestrator`** class
3. **Add API endpoints** in `integrations/apex_api.py`
4. **Update health checks**
5. **Document in this file**

### Testing

```bash
# Run tests
pytest tests/

# Test APEX integration
pytest tests/test_apex_integration.py -v

# Test with coverage
pytest --cov=integrations tests/
```

---

## ğŸ“ Troubleshooting

### Common Issues

**APEX Integration Not Available**
```
WARNING - APEX Integration DISABLED - Install dependencies: pip install httpx
```
**Solution:** `pip install httpx`

**Memory Plugin Connection Failed**
```
Memory Plugin storage failed: Connection refused
```
**Solution:** Start Memory Plugin MCP server: `npx -y @memoryplugin/mcp-server`

**GitHub Token Missing**
```
services: github: âš ï¸ No token
```
**Solution:** Set `GITHUB_TOKEN` environment variable

---

## ğŸŒ Related Documentation

- [Memory Plugin Documentation](https://help.memoryplugin.com)
- [Supermemory AI Docs](https://supermemory.ai)
- [Mem0 API Reference](https://docs.mem0.ai)
- [GitHub MCP Server](https://github.com/modelcontextprotocol/servers)
- [Notion MCP Beta](https://notion.com/mcp)
- [Operator Code MCP](https://operator-code-mcp.vercel.app)

---

## âœ¨ Features

- âœ… **Memory Triad** - Triple redundancy across 3 memory systems
- âœ… **Intelligent Search** - Multi-source unified search
- âœ… **Task Delegation** - Leverage 4,000+ Operator Code tools
- âœ… **Batch Processing** - Parallel file processing
- âœ… **Real-time Health** - Comprehensive system monitoring
- âœ… **Context Preservation** - Global and direct context IDs
- âœ… **96.9% Token Reduction** - Memory-first architecture
- âœ… **Production Ready** - Docker, logging, error handling

---

**Built with â¤ï¸ by GlacierEQ**  
**Context Global:** LFVBLPUL3N8N8K2FLYGCSCKMSMSRHSG9  
**APEX Quantum Entangled Architecture**
