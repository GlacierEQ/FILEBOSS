# DeepSeek-Coder Environment Configuration

# =================================
# MODEL SETTINGS
# =================================
# Model size (base, large, instruct)
MODEL_SIZE=base

# Custom model path (override default path based on MODEL_SIZE)
#MODEL_PATH=/app/models/custom-model

# Quantization type (none, int8, fp16, bf16)
QUANTIZATION_TYPE=none

# =================================
# SERVER SETTINGS
# =================================
# Host and port
HOST=0.0.0.0
PORT=8000

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Number of worker processes
WORKERS=1

# =================================
# SECURITY SETTINGS
# =================================
# Enable API key authentication
ENABLE_AUTH=true

# API keys (comma-separated)
API_KEYS=sk-change-this-key-before-production

# Rate limit per hour per API key
RATE_LIMIT=100

# =================================
# CORS SETTINGS
# =================================
# Allowed origins (comma-separated, * for all)
ALLOW_ORIGINS=*

# Allow credentials
ALLOW_CREDENTIALS=false

# Allowed methods (comma-separated)
ALLOW_METHODS=GET,POST,OPTIONS

# Allowed headers (comma-separated)
ALLOW_HEADERS=Content-Type,Authorization

# =================================
# DIRECTORY SETTINGS
# =================================
# Data directory
DATA_DIR=data

# Log directory
LOG_DIR=logs

# Cache directory
CACHE_DIR=cache

# =================================
# PERFORMANCE SETTINGS
# =================================
# Enable torch.compile optimization
TORCH_COMPILE=true

# Enable Flash Attention (if available)
FLASH_ATTENTION=true

# Maximum batch size for inference
MAX_BATCH_SIZE=4

# Maximum concurrent requests
MAX_CONCURRENT_REQUESTS=4

# Request timeout in seconds
REQUEST_TIMEOUT=300

# =================================
# ELASTICSEARCH SETTINGS
# =================================
# Elasticsearch host
ELASTICSEARCH_HOST=elasticsearch

# Elasticsearch port
ELASTICSEARCH_PORT=9200

# Elasticsearch index prefix
ELASTICSEARCH_INDEX_PREFIX=deepseek-

# =================================
# MONITORING SETTINGS
# =================================
# Enable Prometheus metrics
ENABLE_METRICS=true

# Enable telemetry (anonymous usage stats)
ENABLE_TELEMETRY=true

# Prometheus metrics port
PROMETHEUS_PORT=9090

# =================================
# GPU SETTINGS
# =================================
# Visible CUDA devices (comma-separated or "all")
CUDA_VISIBLE_DEVICES=all

# PyTorch CUDA memory allocation settings
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
